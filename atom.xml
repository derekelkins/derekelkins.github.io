<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Hedonistic Learning</title>
    <link href="https://derekelkins.github.io/atom.xml" rel="self" />
    <link href="https://derekelkins.github.io" />
    <id>https://derekelkins.github.io/atom.xml</id>
    <author>
        <name>Derek Elkins</name>
        <email>derek.a.elkins+blog@gmail.com</email>
    </author>
    <updated>2015-12-04T01:22:52Z</updated>
    <entry>
    <title>High dimensional thought experiment from Hamming</title>
    <link href="https://derekelkins.github.io/posts/high-dimensional-thought-experiment.html" />
    <id>https://derekelkins.github.io/posts/high-dimensional-thought-experiment.html</id>
    <published>2015-12-04T01:22:52Z</published>
    <updated>2015-12-04T01:22:52Z</updated>
    <summary type="html"><![CDATA[<p>This is a simple mathematical thought experiment from Richard Hamming to demonstrate how poor our intuition  for high dimensional spaces is. All that is needed is some basic, middle school level geometry and algebra.  Consider a 2x2 square centered at the origin. In each quadrant place circles as big as possible so that they fit in the square and don’t overlap. They’ll clearly have radius 1/2. See the image below. The question now is what’s the radius of the largest circle centered at the origin that doesn’t overlap the other circles.  <img src="../raw/high-dimensional-diagram.svg" alt=""></img>  It’s clear from symmetry that the inner circle is going to touch all the other circles at the same time, and it is clear that it is going to touch along the line from the origin to the center of one of the outer circles. So the radius of the inner circle, #r#, is just the distance from the origin to the center of one of the outer circles minus the radius of the outer circle, namely 1/2. As an equation:  <code class="asciimath">#r = sqrt(1/2^2 + 1/2^2) - 1/2 = sqrt(2)/2 - 1/2 ~~ 0.207106781#</code>  Now if we go to three dimensions we’ll have eight circles instead of four, but everything else is the same except the distances will now be <code class="asciimath">#sqrt(1/2^2 + 1/2^2 + 1/2^2)#</code>. It’s clear that the only  difference for varying dimensions is that in dimension #n# we’ll have #n# #1/2^2# terms under the square root sign. So the general solution is easily shown to be:  <code class="asciimath">#r = sqrt(n)/2 - 1/2#</code>  You should be weirded out now. If you aren’t, here’s a hint: what happens when #n = 10#? Here’s another hint: what happens as #n# approaches #oo#?</p>]]></summary>
</entry>
<entry>
    <title>Behavioral Reflection</title>
    <link href="https://derekelkins.github.io/posts/behavioral-reflection.html" />
    <id>https://derekelkins.github.io/posts/behavioral-reflection.html</id>
    <published>2015-11-17T00:54:35Z</published>
    <updated>2015-11-17T00:54:35Z</updated>
    <summary type="html"><![CDATA[<h2 id="behavioral-reflection">Behavioral Reflection</h2>
<p>The ultimate goal of behavioral reflection (aka procedural reflection and no doubt other things) is to make a language where programs within the language are able to completely redefine the language as it executes. This is arguably the pinnacle of expressive power. This also means, though, local reasoning about code is utterly impossible, essentially by design.</p>
<p>Smalltalk is probably the language closest to this that is widely used. The Common Lisp MOP (Meta-Object Protocol) is also inspired by research in this vein. The ability to mutate classes and handle calls to missing methods as present in, e.g. Ruby, are also examples of very limited forms of behavioral reflection. (Though, for the latter, often the term “structural reflection” is used instead, reserving “behavioral reflection” for things beyond mere structural reflection.)</p>
<h3 id="very-brief-history">Very Brief History</h3>
<p>The seminal reference for behavioral reflection is Brian Smith’s 1982 <a href="http://publications.csail.mit.edu/lcs/specpub.php?id=840">thesis</a> on 3-LISP. This was followed by the languages <a href="http://cs.au.dk/~hosc/vol01/01-wand-friedman.html">Brown</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.2018&amp;rep=rep1&amp;type=pdf">Blond</a>, <a href="ftp://html.soic.indiana.edu/pub/techreports/TR362.pdf">Refci</a>, and <a href="http://www.is.ocha.ac.jp/~asai/Black/">Black</a> in chronological order. This is not a comprehensive list, and the last time I was in to this was about a decade ago. (Sure enough, there is some new work on Black and some very new citations of Black.)</p>
<!--[Reflection for the Masses](http://www.p-cos.net/documents/s32008.pdf) by Herzeel, Constanza, and D'Hondt.-->
<h3 id="core-idea">Core Idea</h3>
<p>The core idea is simply to expose the state of the (potentially conceptual) interpreter and allow it to be manipulated.</p>
<!--more-->
<p>From this perspective Scheme’s <code>call/cc</code> is a basic, limited example of behavioral reflection. It exposes one part of the state of the interpreter and allows it to be replaced. Delimited continuations (i.e. <code>shift</code> and <code>reset</code>) are a bit more powerful. They expose the same part of the state as <code>call/cc</code>, but they expose it in a more structured manner that allows more manipulations beyond merely replacing it. We could imagine representing the continuation with a less opaque object than a function which would lead to Smalltalk’s <code>MethodContext</code>.</p>
<p>Early Lisps’ fexpr was another example of exposing a different part of the interpreter state, namely the expression under evaluation. The <a href="https://web.cs.wpi.edu/~jshutt/kernel.html">Kernel</a> language explores this in more depth (among other things which can likely also be classified as forms of behavior reflection.)</p>
<p>For a language with mutation the heap would also be exposed. For a language without mutation, mutation can be added using the techniques from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8213&amp;rep=rep1&amp;type=pdf">Representing Monads</a> since something at least as powerful as delimited continuations will almost certainly be available. At that point, the heap would be first-class.</p>
<p>As an aside, I like to use the word “introspection” for purely read-only access to interpreter state, and reserve the word “reflection” for when manipulations are possible. Terminologically, “reflection” is also often broken down into “structural reflection” for the widely available ability to add and remove methods to classes and similar such operations; and “behavioral” or “procedural” reflection, the ability to manipulate the language itself. To control introspection and, at least, structural reflection, <a href="http://www.bracha.org/mirrors.pdf">mirrors</a> can be used.</p>
<!-- Reflective Tower -->
<h3 id="example">Example</h3>
<p>Making a simple behaviorally reflective language is actually pretty straightforward. If you have an abstract machine for your language, all you need to do is provide one additional primitive operation which gets passed the interpreter state and returns a new interpreter state. It may be clearer and cleaner, perhaps, to split this into two operations: one, often called <code>reify</code>, that provides the interpreter state as a value, and another, often called <code>reflect</code>, that sets the interpreter state to the state represented by the given value. Note that both <code>reify</code> and <code>reflect</code> are (very) impure operations. The more tedious part is marshalling the state of the interpreter into a language level object and vice versa. In the special case of a meta-circular interpreter, this part turns out to be trivial. The following interpreter is NOT meta-circular though.</p>
<p>The approach taken in this example, while simple, is very unstructured. For example, it is possible to write a procedure that when evaluated transforms the language from call-by-value (the CEK machine is an implementation of the CbV lambda calculus), to call-by name. However, to do this requires walking all the code in the environment and continuation and rewriting applications to force their first argument and delay their second argument. Primitives also need to be dealt with. It would be far nicer and cleaner to simply be able to say, “when you do an application, do this instead.” The newer behaviorally reflective languages work more like this.</p>
<p>Note, despite the fact that we do a global transformation, this is not an example of lack of expressiveness. We can define this transformation locally and execute it at run-time without coordination with the rest of the code. In this sense, everything is macro expressible (a la <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.4656&amp;rep=rep1&amp;type=pdf">Felleisen</a>) because arbitrary global transformations are macro expressible.</p>
<h3 id="the-code">The Code</h3>
<p>You can get a copy of the full version of the code from <a href="../raw/CEK.hs">here</a>.</p>
<p>I arbitrarily decided to start from the CEK machine: an abstract machine for the untyped call-by-value lambda calculus. (CEK stands for Control-Environment-Kontinuation, these being the three pieces of interpreter state with control being the expression driving evaluation.) While a call-by-value language is probably the way to go because both <code>reify</code> and <code>reflect</code> are very impure operations (particularly <code>reflect</code>), the main motivation for choosing this machine was that the state components correspond in a direct way to concepts that are natural to the programmer. Compare this to the SECD machine which stands for Stack-Environment-Control-Dump.</p>
<p>The AST uses deBruijn indices.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Expr</span> 
    <span class="fu">=</span> <span class="dt">EVar</span> <span class="fu">!</span><span class="dt">Int</span> 
    <span class="fu">|</span> <span class="dt">ELam</span> <span class="dt">Expr</span> 
    <span class="fu">|</span> <span class="dt">Expr</span> <span class="fu">:@:</span> <span class="dt">Expr</span></code></pre></div>
<p>The only types of values we have are closures. The two additional pieces of interpreter state are the environment and the continuation (the call stack).</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Value</span> <span class="fu">=</span> <span class="dt">Closure</span> <span class="dt">Expr</span> <span class="dt">Env</span>

<span class="kw">type</span> <span class="dt">Env</span> <span class="fu">=</span> [<span class="dt">Value</span>]

<span class="kw">data</span> <span class="dt">Kont</span> <span class="fu">=</span> <span class="dt">Done</span> <span class="fu">|</span> <span class="dt">Arg</span> <span class="dt">Expr</span> <span class="dt">Env</span> <span class="dt">Kont</span> <span class="fu">|</span> <span class="dt">Fun</span> <span class="dt">Value</span> <span class="dt">Kont</span></code></pre></div>
<p>Finally the evaluator is fairly straightforward, and is a straightforward transcription of the operational semantics. Evaluation starts off with the final contination and an empty environment. With a bit of inspection you can see that evaluation is call-by-value and proceeds left-to-right. Derive <code class="sourceCode haskell"><span class="dt">Show</span></code> for <code class="sourceCode haskell"><span class="dt">Expr</span></code> and <code class="sourceCode haskell"><span class="dt">Value</span></code> and these 15 lines of code are a complete interpreter.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">evaluate ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">Value</span>
evaluate e <span class="fu">=</span> cek e [] <span class="dt">Done</span>

<span class="ot">cek ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">Env</span> <span class="ot">-&gt;</span> <span class="dt">Kont</span> <span class="ot">-&gt;</span> <span class="dt">Value</span>
cek (<span class="dt">EVar</span> i)  env                         k <span class="fu">=</span> cek e env&#39; k <span class="kw">where</span> <span class="dt">Closure</span> e env&#39; <span class="fu">=</span> env <span class="fu">!!</span> i
cek (f <span class="fu">:@:</span> x) env                         k <span class="fu">=</span> cek f env (<span class="dt">Arg</span> x env k)
cek (<span class="dt">ELam</span> b)  env                      <span class="dt">Done</span> <span class="fu">=</span> <span class="dt">Closure</span> b env
cek (<span class="dt">ELam</span> b)  env            (<span class="dt">Arg</span> x env&#39; k) <span class="fu">=</span> cek x env&#39; (<span class="dt">Fun</span> (<span class="dt">Closure</span> b env) k)
cek (<span class="dt">ELam</span> b)  env (<span class="dt">Fun</span> (<span class="dt">Closure</span> b&#39; env&#39;) k) <span class="fu">=</span> cek b&#39; (<span class="dt">Closure</span> b env<span class="fu">:</span>env&#39;) k</code></pre></div>
<p>The first stab at adding reflective features looks like this. We add the primitive operation to reify and reflect. We’ll require them to be wrapped in lambdas so the interpreter doesn’t have to deal with unevaluated arguments when interpreting them. Note that <code class="sourceCode haskell">reify</code> doesn’t pass the <code class="sourceCode haskell"><span class="dt">Expr</span></code> part to its argument. This is because the <code class="sourceCode haskell"><span class="dt">Expr</span></code> part would just be <code class="sourceCode haskell"><span class="dt">EReify</span></code>. The arguments of this particular application are stored, unevaluated, in the continuation as arguments needing to be evaluated. So, if we want to define <code class="sourceCode haskell">quote</code> which simply returns the expression representing it’s argument, we’ll have to dig into the continuation to get that argument.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Expr</span>
    <span class="fu">=</span> <span class="fu">...</span>
    <span class="fu">|</span> <span class="dt">EReify</span>
    <span class="fu">|</span> <span class="dt">EReflect</span>

<span class="co">-- reify f = f e k</span>
reify <span class="fu">=</span> <span class="dt">ELam</span> <span class="dt">EReify</span>

<span class="co">-- reflect c e k</span>
reflect <span class="fu">=</span> <span class="dt">ELam</span> (<span class="dt">ELam</span> (<span class="dt">ELam</span> <span class="dt">EReflect</span>))</code></pre></div>
<p>And here’s what we’d like to write in the interpreter (and is very close to what we ultimately will write.)</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">cek ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">Env</span> <span class="ot">-&gt;</span> <span class="dt">Kont</span> <span class="ot">-&gt;</span> <span class="dt">Value</span>
<span class="fu">...</span>
cek <span class="dt">EReify</span>   (<span class="dt">Closure</span> b env&#39;<span class="fu">:</span>env) k <span class="fu">=</span> cek b (k<span class="fu">:</span>env<span class="fu">:</span>env&#39;) k
cek <span class="dt">EReflect</span> (k<span class="fu">:</span>e<span class="fu">:</span>c<span class="fu">:</span>_)            _ <span class="fu">=</span> cek c            e k</code></pre></div>
<p>There are two problems with this code: one minor and one major. The minor problem is that the argument to <code class="sourceCode haskell">reify</code> takes two arguments but we can’t just pass them directly to it. We need to follow our calling convention which expects to evaluate arguments one at a time. This problem is easily fixed by pushing an <code class="sourceCode haskell"><span class="dt">Arg</span></code> call stack frame onto the continuation to (trivially) evaluate the continuation.</p>
<p>The major problem is that this doesn’t type check. <code>c</code>, <code>e</code>, <code>env</code>, and <code>k</code> can’t simultaneously be <code class="sourceCode haskell"><span class="dt">Value</span></code>s and <code class="sourceCode haskell"><span class="dt">Expr</span></code>s, <code class="sourceCode haskell"><span class="dt">Env</span></code>s, and <code class="sourceCode haskell"><span class="dt">Kont</span></code>s. We need a way to embed and project <code class="sourceCode haskell"><span class="dt">Expr</span></code>, <code class="sourceCode haskell"><span class="dt">Env</span></code>, and <code class="sourceCode haskell"><span class="dt">Kont</span></code> value into and out of <code class="sourceCode haskell"><span class="dt">Value</span></code>. The embedding is easy; you just fold over the data structure and build up a lambda term representing the Church encoding. The projection from <code class="sourceCode haskell"><span class="dt">Value</span></code>s is… non-obvious, to say the least.</p>
<p>Instead of figuring that out, we can simply add <code class="sourceCode haskell"><span class="dt">Expr</span></code>, <code class="sourceCode haskell"><span class="dt">Env</span></code>, and <code class="sourceCode haskell"><span class="dt">Kont</span></code> to our language as primitive types. This is also, almost certainly, dramatically more efficient.</p>
<p>We extend our AST and <code class="sourceCode haskell"><span class="dt">Value</span></code>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Expr</span>
    <span class="fu">=</span> <span class="fu">...</span>
    <span class="fu">|</span> <span class="dt">EInject</span> <span class="dt">Value</span>

<span class="co">-- Int so we can manipulate the EVar case.</span>
<span class="kw">data</span> <span class="dt">Value</span> <span class="fu">=</span> <span class="dt">Closure</span> <span class="dt">Expr</span> <span class="dt">Env</span> <span class="fu">|</span> <span class="dt">Int</span> <span class="fu">!</span><span class="dt">Int</span> <span class="fu">|</span> <span class="dt">Expr</span> <span class="dt">Expr</span> <span class="fu">|</span> <span class="dt">Env</span> <span class="dt">Env</span> <span class="fu">|</span> <span class="dt">Kont</span> <span class="dt">Kont</span></code></pre></div>
<p>The changes to the interpreter are minimal. We need to change the <code class="sourceCode haskell"><span class="dt">EVar</span></code> case to handle the new kinds of values that can be returned and add a trivial <code class="sourceCode haskell"><span class="dt">EInject</span></code> case. Some cases can be omitted because they would only come up in programs that would “get stuck” anyway. (In our case, “getting stuck” means pattern match failure or index out of bounds.)</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">inject ::</span> <span class="dt">Value</span> <span class="ot">-&gt;</span> (<span class="dt">Expr</span>, <span class="dt">Env</span>)
inject (<span class="dt">Closure</span> b env) <span class="fu">=</span> (<span class="dt">ELam</span> b, env)
inject v <span class="fu">=</span> (<span class="dt">EInject</span> v, [])
 
<span class="ot">cek ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">Env</span> <span class="ot">-&gt;</span> <span class="dt">Kont</span> <span class="ot">-&gt;</span> <span class="dt">Value</span>
cek (<span class="dt">EVar</span> i) env k <span class="fu">=</span> cek e env&#39; k <span class="kw">where</span> (e, env&#39;) <span class="fu">=</span> inject (env <span class="fu">!!</span> i)
<span class="fu">...</span>
cek <span class="dt">EReify</span> (<span class="dt">Closure</span> b env&#39;<span class="fu">:</span>env) k <span class="fu">=</span> cek b (<span class="dt">Env</span> env<span class="fu">:</span>env&#39;) (<span class="dt">Arg</span> (<span class="dt">EInject</span> (<span class="dt">Kont</span> k)) [] k)
cek <span class="dt">EReflect</span> (<span class="dt">Kont</span> k<span class="fu">:</span><span class="dt">Env</span> e<span class="fu">:</span><span class="dt">Expr</span> c<span class="fu">:</span>_) _ <span class="fu">=</span> cek c e k
cek (<span class="dt">EInject</span> v) _ <span class="dt">Done</span> <span class="fu">=</span> v
cek (<span class="dt">EInject</span> v) _ (<span class="dt">Fun</span> (<span class="dt">Closure</span> b&#39; env&#39;) k) <span class="fu">=</span> cek b&#39; (v<span class="fu">:</span>env&#39;) k</code></pre></div>
<p>While this interpreter achieves the goal, it is somewhat limited. We don’t have any means to manipulate the values of these new primitive types, so our manipulation of the interpreter state is limited to replacing a component, e.g. the environment, with some version of it that we got before via <code class="sourceCode haskell">reify</code>. Though it may be limited, it is not trivial. You can implement something close to call/cc if not call/cc itself.</p>
<p>Still, the scenario above of turning the language into a call-by-name language doesn’t seem possible. Modifying the interpreter to support primitive operations defined in Haskell is a simple matter of programming: you add a constructor for primitive operations to the AST, you make a very slight variant of the <code class="sourceCode haskell"><span class="dt">EInject</span></code> case in <code class="sourceCode haskell">cek</code>, and then you tediously make primitives corresponding to each constructor for each type and a fold for each type. See the linked <a href="../raw/CEK.hs">source file</a> for the details.</p>
<p>The file additionally defines a pretty printer and a layer using parametric higher-order abstract syntax because humans are terrible with deBruijn indices. The end result is code that looks like this:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">one <span class="fu">=</span> _<span class="dt">Suc</span> <span class="fu">:@</span> _<span class="dt">Zero</span>

identity <span class="fu">=</span> lam (\x <span class="ot">-&gt;</span> x)

loop <span class="fu">=</span> lam (\x <span class="ot">-&gt;</span> x <span class="fu">:@</span> x) <span class="fu">:@</span> lam (\x <span class="ot">-&gt;</span> x <span class="fu">:@</span> x)

tailEnv <span class="fu">=</span> lam (\e <span class="ot">-&gt;</span> paraEnv <span class="fu">:@</span> e <span class="fu">:@</span> _<span class="dt">Nil</span> 
                                  <span class="fu">:@</span> lam (\_ <span class="ot">-&gt;</span> lam (\x <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> x))))

tailKont <span class="fu">=</span> lam (\k <span class="ot">-&gt;</span> paraKont <span class="fu">:@</span> k <span class="fu">:@</span> _<span class="dt">Done</span>
                                    <span class="fu">:@</span> lam (\_ <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> lam (\x <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> x))))
                                    <span class="fu">:@</span> lam (\_ <span class="ot">-&gt;</span> lam (\x <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> x))))

eval <span class="fu">=</span> lam (\c <span class="ot">-&gt;</span> reify <span class="fu">:@</span> lam (\e <span class="ot">-&gt;</span> lam (\k <span class="ot">-&gt;</span> reflect <span class="fu">:@</span> c <span class="fu">:@</span> (tailEnv <span class="fu">:@</span> e) <span class="fu">:@</span> k)))

quote <span class="fu">=</span> reify <span class="fu">:@</span> lam (\e <span class="ot">-&gt;</span> lam (\k <span class="ot">-&gt;</span> reflect <span class="fu">:@</span> (_<span class="dt">Inject</span> <span class="fu">:@</span> c k) <span class="fu">:@</span> e <span class="fu">:@</span> (tailKont <span class="fu">:@</span> k)))
    <span class="kw">where</span> c k <span class="fu">=</span> paraKont <span class="fu">:@</span> k <span class="fu">:@</span> garbage 
                              <span class="fu">:@</span> lam (\x <span class="ot">-&gt;</span> (lam (\_ <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> x))))) 
                              <span class="fu">:@</span> lam (\_ <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> garbage)))
          garbage <span class="fu">=</span> _<span class="dt">Inject</span> <span class="fu">:@</span> _<span class="dt">Zero</span>

callCC <span class="fu">=</span> lam (\f <span class="ot">-&gt;</span> reify <span class="fu">:@</span> lam (\e <span class="ot">-&gt;</span> lam (\k <span class="ot">-&gt;</span> 
            f <span class="fu">:@</span> lam (\a <span class="ot">-&gt;</span> reflect <span class="fu">:@</span> (_<span class="dt">Inject</span> <span class="fu">:@</span> a) <span class="fu">:@</span> (tailEnv <span class="fu">:@</span> e) <span class="fu">:@</span> k))))

example1 <span class="fu">=</span> evaluate <span class="fu">$</span> quote <span class="fu">:@</span> loop <span class="co">-- output looks like: Expr ((\a -&gt; a a) (\a -&gt; a a))</span>
example2 <span class="fu">=</span> evaluate <span class="fu">$</span> eval <span class="fu">:@</span> (quote <span class="fu">:@</span> loop) <span class="co">-- loops forever</span>
example3 <span class="fu">=</span> evaluate <span class="fu">$</span> callCC <span class="fu">:@</span> lam (\k <span class="ot">-&gt;</span> k <span class="fu">:@</span> one <span class="fu">:@</span> loop) <span class="co">-- escape before evaluating the loop</span>
example4 <span class="fu">=</span> evaluate <span class="fu">$</span> callCC <span class="fu">:@</span> lam (\k <span class="ot">-&gt;</span> lam (\_ <span class="ot">-&gt;</span> loop) <span class="fu">:@</span> (k <span class="fu">:@</span> one)) <span class="co">-- also escape before the loop</span></code></pre></div>]]></summary>
</entry>
<entry>
    <title>You know more about presheaves than you think</title>
    <link href="https://derekelkins.github.io/posts/you-know-more-about-presheaves-than-you-think.html" />
    <id>https://derekelkins.github.io/posts/you-know-more-about-presheaves-than-you-think.html</id>
    <published>2015-11-02T12:04:45Z</published>
    <updated>2015-11-02T12:04:45Z</updated>
    <summary type="html"><![CDATA[<h3 id="the-category-of-graphs-as-a-presheaf">The category of graphs as a presheaf</h3>
<p>Here’s a small example of why people find category theory interesting. Consider the category, call it |ccC|, consisting of two objects, which we’ll imaginatively name |0| and |1|, and two non-identity arrows |s,t : 0 -&gt; 1|. The category of graphs (specifically directed multigraphs with loops) is the category of presheaves over |ccC|, which is to say, it’s the category of contravariant functors from |ccC| to <code class="asciimath">|cc&quot;Set&quot;|</code>. I’ll spell out what that means momentarily, but first think about what has been done. We’ve provided a complete definition of not only graphs but the entire category of graphs and graph homomorphisms given you’re familiar with very basic category theory<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. This is somewhat magical.</p>
<p>Spelling things out, |G| is a contravariant functor from |ccC| to <code class="asciimath">|cc&quot;Set&quot;|</code>. This means that |G| takes each object of |ccC| to a set, i.e. |G(0) = V| and |G(1) = E| for arbitrary sets |V| and |E|, but which will represent the vertices and edges of our graph. In addition, |G| takes the arrows in |ccC| to a (set) function, but, because it’s contravariant, it flips the arrows around. So we have, for example, |G(s) : G(1) -&gt; G(0)| or |G(s) : E -&gt; V|, and similarly for |t|. |G(s)| is a function that takes an edge and gives its source vertex, and |G(t)| gives the target. The arrows in the category of graphs are just natural transformations between the functors. In this case, that means if we have two graphs |G| and |H|, a graph homomorphism |f : G -&gt; H| is a pair of functions |f_0 : G(0) -&gt; H(0)| and |f_1 : G(1) -&gt; H(1)| that satisfy |H(s) @ f_1 = f_0 @ G(s)| and |H(t) @ f_1 = f_0 @ G(t)|. With a bit of thought you can see that all this says is that we must map the source and target of an edge |e| to the source and target of the edge |f_1(e)|. You may also have noticed that <em>any</em> pair of sets and pair of functions between them is a graph. In other words, graphs are very simple things. This takes out a lot of the magic, though it is nice that we get the right notion of graph homomorphism for free. Let me turn the magic up to 11.</p>
<!--more-->
<p>Presheaves are extremely important in category theory, so categorists know a lot about them. It turns out that they have a lot of structure (mostly because <code class="asciimath">|cc&quot;Set&quot;|</code> has a lot of structure). In particular, in the categorical jargon, if |ccC| is small (and finite is definitely small), then the category of presheaves over |ccC| is a complete and cocomplete elementary topos with a natural number object. For those of you learning category theory who’ve gotten beyond the basics, proving this is a <em>very</em> good and important exercise. In programmer-speak, that says we can do dependently typed lambda calculus with algebraic data and codata types in that category. To be clear, this is not saying we have a lambda calculus with a graph type. It’s saying we have a lambda calculus where <em>all</em> our types have graph structure.</p>
<h3 id="beyond-graphs">Beyond graphs</h3>
<p>But set that aside for now. This isn’t an article about graphs so let’s start generalizing away from them. We’ll start with a baby step. You can probably guess how we’d go about making edge labeled graphs. We’d add another object to |ccC|, say |2|, and an arrow from |2| to |1|, call it |l_e| — remember that the arrows are “backwards” because presheaves are contravariant. You may start seeing a pattern already. One way to start formalizing that pattern is to say for every object of |ccC| we have an abstract data type with a field for each arrow into that object. In our example, |1| has three arrows into it, namely |s|, |t|, and |l_e|. We can view an element |e in F(1)| for a presheaf |F| as having fields <code>e.s</code>, <code>e.t</code> and <code>e.l_e</code>. Since <code class="asciimath">|cc&quot;Set&quot;|</code> has (non-constructive, non-computable) decidable equality for everything, we can tell |e| from |e’| even if <code>e.s = e'.s</code> and <code>e.t = e'.t</code> and <code>e.l_e = e'.l_e</code>. This is different from a normal abstract data type (in a purely functional language) where an abstract data type with three fields would be isomorphic to a 3-tuple. The extra ability to differentiate them could be modeled by having a fourth field that returned something that could only be compared for equality, kind of like <a href="https://hackage.haskell.org/package/base/docs/Data-Unique.html">Data.Unique</a> (ignoring the <code>Ord</code> instance…) It may look like:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Vertex</span> <span class="co">-- abstract</span>
<span class="ot">vertexId ::</span> <span class="dt">Vertex</span> <span class="ot">-&gt;</span> <span class="dt">Unique</span>

<span class="kw">data</span> <span class="dt">Label</span> <span class="co">-- abstract</span>
<span class="ot">labelId ::</span> <span class="dt">Label</span> <span class="ot">-&gt;</span> <span class="dt">Unique</span>

<span class="kw">data</span> <span class="dt">Edge</span> <span class="co">-- abstract</span>
<span class="ot">edgeId ::</span> <span class="dt">Edge</span> <span class="ot">-&gt;</span> <span class="dt">Unique</span>
<span class="ot">src ::</span> <span class="dt">Edge</span> <span class="ot">-&gt;</span> <span class="dt">Vertex</span>
<span class="ot">tgt ::</span> <span class="dt">Edge</span> <span class="ot">-&gt;</span> <span class="dt">Vertex</span>
<span class="ot">label ::</span> <span class="dt">Edge</span> <span class="ot">-&gt;</span> <span class="dt">Label</span></code></pre></div>
<p>Of course, if these are literally all the functions we have for these types (plus some constants otherwise we can’t make anything), then these abstract types might as well be records. Anything else they have is unobservable and thus superfluous.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Vertex</span> <span class="fu">=</span> <span class="dt">Vertex</span> {<span class="ot"> vertexId ::</span> <span class="dt">Unique</span> }

<span class="kw">data</span> <span class="dt">EdgeLabel</span> <span class="fu">=</span> <span class="dt">EdgeLabel</span> {<span class="ot"> edgeLabelId ::</span> <span class="dt">Unique</span> }

<span class="kw">data</span> <span class="dt">Edge</span> <span class="fu">=</span> <span class="dt">Edge</span> { 
<span class="ot">    edgeId ::</span> <span class="dt">Unique</span>, 
<span class="ot">    src ::</span> <span class="dt">Vertex</span>, 
<span class="ot">    tgt ::</span> <span class="dt">Vertex</span>,
<span class="ot">    edgeLabel ::</span> <span class="dt">EdgeLabel</span>
}</code></pre></div>
<p>This starts to suggest that we can just turn each object in our category |ccC| into a record with an ID field. Each arrow in to that object becomes an additional field. This almost works. We’ll come back to this, but let’s take another baby step.</p>
<p>Something a bit more interesting happens if we want to label the vertices. We proceed as before: add another object, call it |3|, and another arrow |l_v : 3 -&gt; 0|. This time, though, we’re not finished. |ccC| is supposed to be a category, so we can compose arrows and thus we have two composites but no arrow for the composites to be, namely: |s @ l_v| and |t @ l_v|. The abstract data type intuition suggests that whenever we run into this situation, we should add a distinct arrow for each composite. For the purpose of labeling vertices, this is the right way to go: we want to think of each vertex as having a vertex label field with no constraints. There is, however, another choice. We could add <em>one</em> new arrow and have both composites be equal to it. What that would say is that for every edge, the source and the target vertices must have the same label. It’s easy to see that that would lead to every vertex in a connected component having the same label. In code, the former choice would look like:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">VertexLabel</span> <span class="fu">=</span> <span class="dt">VertexLabel</span> {<span class="ot"> vertexLabelId ::</span> <span class="dt">Unique</span> }

<span class="kw">data</span> <span class="dt">Vertex</span> <span class="fu">=</span> <span class="dt">Vertex</span> { 
<span class="ot">    vertexId ::</span> <span class="dt">Unique</span>,
<span class="ot">    vertexLabel ::</span> <span class="dt">VertexLabel</span>
}

<span class="kw">data</span> <span class="dt">EdgeLabel</span> <span class="fu">=</span> <span class="dt">EdgeLabel</span> {<span class="ot"> edgeLabelId ::</span> <span class="dt">Unique</span> }

<span class="kw">data</span> <span class="dt">Edge</span> <span class="fu">=</span> <span class="dt">Edge</span> { 
<span class="ot">    edgeId ::</span> <span class="dt">Unique</span>, 
<span class="ot">    src ::</span> <span class="dt">Vertex</span>, 
<span class="ot">    tgt ::</span> <span class="dt">Vertex</span>,
<span class="ot">    edgeLabel ::</span> <span class="dt">EdgeLabel</span>
    <span class="co">-- With our earlier &quot;rule&quot; to add a field for each arrow</span>
    <span class="co">-- we should also have:</span>
    <span class="co">--    srcVertexLabel :: VertexLabel</span>
    <span class="co">--    tgtVertexLabel :: VertexLabel</span>
    <span class="co">-- but, by definition, these are:</span>
    <span class="co">--    vertexLabel . src and</span>
    <span class="co">--    vertexLabel . tgt respectively.</span>
    <span class="co">-- So we don&#39;t explicitly add a field for composite arrows.</span>
}</code></pre></div>
<p>The latter choice would look the same, except there would be an extra constraint that we can’t capture in Haskell, namely <code class="sourceCode haskell">vertexLabel <span class="fu">.</span> src <span class="fu">==</span> vertexLabel <span class="fu">.</span> tgt</code>.</p>
<p>If we stick to the abstract data type intuition and we have a cycle in the arrows in |ccC|, then the requirement to add a distinct arrow for each composite means we need to add a countably infinite number of arrows, so |ccC| is no longer finite. It is still “small” though, so that’s no problem. We could say we have a finite <em>graph</em> of the non-composite arrows and possibly some equations like |s @ l_v = t @ l_v| and we generate a category from that graph subject to those equations by adding in all composites as necessary. We will use the arrows in this graph to decide on the fields for our abstract data types, rather than the arrows in the category so we don’t end up with an infinity of fields in our data types. Even when there aren’t an infinite number of arrows in our category, this is still useful since we aren’t going to add a field to our edges to hold each vertex’s label, since we can just get the vertex and then get the label.</p>
<p>Some of you have probably thought of another more appropriate intuition. A presheaf is a database. The category which our presheaf is over, what we’ve been calling |ccC| <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> is sort of like a schema. You don’t specify types, but you do specify foreign key relationships plus some additional integrity constraints that don’t fit in to the typical ones supported by databases.</p>
<h3 id="presheaves-as-databases">Presheaves as databases</h3>
<p>For our earlier example:</p>
<div class="sourceCode"><pre class="sourceCode sql"><code class="sourceCode sql"><span class="kw">CREATE</span> VertexLabel (<span class="kw">Id</span> uniqueidentifier <span class="kw">PRIMARY</span> <span class="kw">KEY</span>);
<span class="kw">CREATE</span> Vertex (
    <span class="kw">Id</span> uniqueidentifier <span class="kw">PRIMARY</span> <span class="kw">KEY</span>,
    <span class="kw">Label</span> uniqueidentifier <span class="kw">REFERENCES</span> VertexLabel(<span class="kw">Id</span>)
);
<span class="kw">CREATE</span> EdgeLabel (<span class="kw">Id</span> uniqueidentifier <span class="kw">PRIMARY</span> <span class="kw">KEY</span>);
<span class="kw">CREATE</span> Edge (
    <span class="kw">Id</span> uniqueidentifier <span class="kw">PRIMARY</span> <span class="kw">KEY</span>,
    Src uniqueidentifier <span class="kw">REFERENCES</span> VertexLabel(<span class="kw">Id</span>),
    Tgt uniqueidentifier <span class="kw">REFERENCES</span> VertexLabel(<span class="kw">Id</span>),
    <span class="kw">Label</span> uniqueidentifier <span class="kw">REFERENCES</span> EdgeLabel(<span class="kw">Id</span>)
    <span class="co">-- Nothing stops us from having additional columns here and elsewhere</span>
    <span class="co">-- corresponding to the fact that our types were really abstract data</span>
    <span class="co">-- types in the Haskell, and to the fact that we can choose an arbitrary</span>
    <span class="co">-- set as long as it has at least this much structure.  They won&#39;t be</span>
    <span class="co">-- preserved by &quot;homomorphisms&quot; though.</span>
);</code></pre></div>
<p>To be clear, each presheaf corresponds to a database <em>with data</em>. Inserting a row into a table is a homomorphism of presheaves, but so is adding a (not preserved by homomorphism) column. The schema above corresponds to the |ccC| part of the presheaf.</p>
<p>If we had made that second choice before where we had only <em>one</em> arrow back that would lead to the following integrity constraint:</p>
<div class="sourceCode"><pre class="sourceCode sql"><code class="sourceCode sql"><span class="kw">NOT</span> <span class="kw">EXISTS</span>(<span class="kw">SELECT</span> *
           <span class="kw">FROM</span> Edge e
           <span class="kw">JOIN</span> Vertex src <span class="kw">ON</span> e.Src = src.Id
           <span class="kw">JOIN</span> Vertex tgt <span class="kw">ON</span> e.Tgt = tgt.Id
           <span class="kw">WHERE</span> src.Label &lt;&gt; tgt.Label)</code></pre></div>
<p>It turns out this intuition is completely general. You can actually think of all of presheaf theory as a (slightly unusual) database theory. More objects just means more tables. More arrows means more foreign keys and potentially additional integrity constraints. It’s not exactly relational though. In fact, in some ways it’s a bit closer to SQL<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> or object databases. You can turn this around too going back to the point at the beginning. Whether or not we can think of <em>all</em> presheaves like databases or all databases like presheaves, we can certainly think of <em>this</em> example, and many like it, as presheaves. This means for many “databases”, we can talk about doing dependently typed programming where our types <em>are</em> databases of the given shape. This also dramatically shifts the focus in database theory from databases to database migrations, i.e. homomorphisms of databases.</p>
<p>David Spivak is the one who has done the most on this, so I’ll refer you to his <a href="http://math.mit.edu/~dspivak/informatics/pure/">work</a>. He also has a better story for schemas that are much closer to normal schemas. I’ll end as I began:</p>
<p>Here’s a small example of why people find category theory interesting.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>“very basic category theory” means knowing the definitions of categories, isomorphisms, functors, and natural transformations<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>remember the presheaf is the <em>functor</em> from |ccC^(op) -&gt; cc“Set”|<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>SQL is hardly the relational ideal<a href="#fnref3">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>The three styles of category theory</title>
    <link href="https://derekelkins.github.io/posts/styles-of-category-theory.html" />
    <id>https://derekelkins.github.io/posts/styles-of-category-theory.html</id>
    <published>2015-09-30T05:45:11Z</published>
    <updated>2015-09-30T05:45:11Z</updated>
    <summary type="html"><![CDATA[<h3 id="introduction">Introduction</h3>
<p>Arguably (1-)category theory is the study of universal properties. There are three standard formulations of the notion of universal property which are all equivalent. Most introductions to category theory will cover all three and how they relate. By systematically preferring one formulation above the others, three styles of doing category theory arise with distinctive constructions and proof styles.</p>
<p>I noticed this trichotomy many years ago, but I haven’t heard anyone explicitly identify and compare these styles. Furthermore, in my opinion, one of these styles, the one I call <strong>Set</strong>-category theory, is significantly easier to use than the others, but seems poorly represented in introductions to category theory.</p>
<p>For myself, it wasn’t until I read <a href="http://www.tac.mta.ca/tac/reprints/articles/10/tr10abs.html">Basic Concepts of Enriched Category Theory</a> by G. M. Kelly and was introduced to indexed (co)limits (aka weighted (co)limits), that I began to recognize and appreciate <strong>Set</strong>-category theory. Indexed (co)limits are virtually absent from category theory introductions, and the closely related notion of (co)ends are also very weakly represented despite being far more useful than (conical) (co)limits. I don’t know why this is. Below I’ll be more focused on comparing the styles than illustrating the usefulness of indexed (co)limits. I may write an article about that in the future; in the mean time you can read “Basic Concepts of Enriched Category Theory” and just ignore the enriched aspect. Admittedly, it is definitely <em>not</em> an introduction to category theory.</p>
<!--more-->
<h3 id="universality">Universality</h3>
<p>What follows are three equivalent formulations of the notion of universal property including proofs of equivalence.</p>
<h4 id="initiality">Initiality</h4>
<p>Initiality is by far the simplest formulation of universal properties to understand because it is a very special case, albeit a special case that can be finagled to cover the general case.</p>
<p>An object, typically denoted |0|, is <strong>initial</strong> iff for every object in the category there exists a unique arrow from |0|. If |A| is an object in the category, we can write |(:A:) : 0 -&gt; A| for the unique arrow.</p>
<h4 id="representability">Representability</h4>
<p>Representability isn’t as simple or intuitive as initiality, but it is still pretty simple.</p>
<p>A functor |F : C^(op) -&gt; Set| is <strong>representable</strong> iff |F ~= Hom(-,Y)| for some |Y|. Note that this is an isomorphism between functors, i.e. a natural isomorphism. We say |Y| <strong>represents</strong> the functor |F|. A functor |G : C -&gt; Set| is <strong>co-representable</strong> iff |G ~= Hom(X,-)| for some |X|. Similarly we say |X| <strong>(co-)represents</strong> the functor |G|. Representable and co-representable aren’t actually different; if we set |D = C^(op)| then we could say |F| is co-representable as a functor from |D| and it would mean the same thing.</p>
<p>Now we need to prove initiality and (co-)representability equivalent. One direction is easy, |0| co-represents the functor |lambda C . {**}|.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> It’s easy to show that this says exactly that |0| is initial.</p>
<p>I’ll hold off on the other direction and instead prove the circular implication: <strong>Representability</strong> |=&gt;| <strong>Initiality</strong> |=&gt;| <strong>Universal Arrow</strong> |=&gt;| <strong>Representability</strong>. Right now we’ve done the first step; we can recast initiality as representability. Next we’ll show that we can recast universal arrows as initiality and representability as a universal arrow and we’ll have shown them all equivalent.</p>
<h4 id="universal-arrow">Universal arrow</h4>
<p>Let |U : C -&gt; D| be a functor. |eta : A -&gt; UX| is a <strong>universal arrow</strong> iff for all |f : A -&gt; UY| there exists a unique arrow |(:f:) : X -&gt; Y| such that |f = U(:f:) @ eta|. Dually, let |F : C -&gt; D| be a functor, then |epsilon : FX -&gt; A| is a <strong>co-universal arrow</strong> iff for all |g : FY -&gt; A| there exists a unique arrow |(:g:) : Y -&gt; X| such that |g = epsilon @ F(:g:)|. Again, these are equivalent notions. A co-universal arrow is just a universal arrow in the opposite category.</p>
<p>Now to prove <strong>Initiality</strong> |=&gt;| <strong>Universal Arrow</strong>. Consider the (comma) category whose objects are pairs |(f, Y)| where |f : A -&gt; UY| and whose arrows |k : (f, Y) -&gt; (g, Z)| are arrows |k : Y -&gt; Z| such that |g = Uk @ f|. |eta| is a universal arrow iff |(eta, X)| is initial in this category. This is easy to check.</p>
<p>Finally, <strong>Universal Arrow</strong> |=&gt;| <strong>Representability</strong>. Let |G : C -&gt; Set|. The claim is there exists a universal arrow <code class="asciimath">|eta : {**} -&gt; GX|</code> iff |X| co-represents |G|. Doing the backwards direction first, if |X| co-represents |G| then there is an element of |GX| that corresponds to |id : X -&gt; X|. Have |eta| pick out that element. Given another element |y : {**} -&gt; GY| we need to find a unique arrow |(:y:) : X -&gt; Y| such that |G(:y:)(eta) = y|. Naturality of the isomorphism making |X| co-represent |G| says: |f @ phi_A(a) = phi_B(Gf(a))| where |phi : G ~= Hom(X,-)|, |f : A -&gt; B|, and |a in GA|. Applying |phi_Y| to both sides of the earlier equation and using |phi_X(eta) = id| we get: |(:y:) = phi_Y(y)| showing that |(:y:)| exists and is unique and thus |eta| is a universal arrow.</p>
<p>Next we need to show that |eta : {**} -&gt; GX| being a universal arrow implies that |X| co-represents |G|. We immediately have a parameterized bijection namely |(: - :)_Y : GY ~= Hom(X,Y)|. All we need to do is show that it is natural in |Y| which is to say |f @ (:a:)_A = (:Gf(a):)_B| where |f : A -&gt; B|. We have |Gf(a) = Gf(G(:a:)(eta)) = (Gf @ G(:a:))(eta) = G(f @ (:a:))(eta)|. Using |f = (:Gf(eta):)_B| which is a consequence of |eta| being universal, we get |(:Gf(a):)_B = f @ (:a:)_A| as desired.</p>
<h3 id="initiality-1">Initiality</h3>
<p>In the initiality style of doing category theory, the main exercise is defining an appropriate category. This is pretty difficult from both a creativity perspective and a notational perspective. Once an appropriate category is defined, though, the proofs are typically not too hard. Perhaps the main tool is the comma category as that allows the compact and flexible specification of many categories, though it can often take a touch of creativity to recognize a category as a comma category. Technically, the proof above implies that for any universal property there’s an appropriate comma category in which the universal object is the initial object.</p>
<p>This style is often seen in introductions to category theory. If you’ve ever read about categories of (co)cones or wedges, then you’ve seen an example of this style with an ad-hoc definition of the relevant categories. In practice, the categories needed to characterize a specific universal property are of little interest on their own so the effort spent defining them isn’t repaid. The main exception is the category of |F|-algebras for some functor |F|. (Incidentally, the category of |F|-algebras is a full subcategory of a comma category.)</p>
<p>The style of proof is to leverage the uniqueness of the mediating morphism to equate two seemingly different things. Lambek’s lemma is an excellent illustration of this proof style.</p>
<h3 id="set-category-theory"><strong>Set</strong>-category theory</h3>
<p>The core of this style of category theory is representability and its parameterized variant. Representability alone is already very powerful and ergonomic. Every limit or colimit in a category represents a limit of homsets. This means all the tools and intuitions of set theory are available. This is the basis for my naming of this style: we elucidate the structure of a category by relating it to the structure of the category of sets.</p>
<p>The main tools of this style are (co)ends, indexed (co)limits, and adjunctions in the form |Hom(FA,B) ~= Hom(A,UB)|. In particular, the intimate connection between ends/indexed limits and sets of natural transformations significantly eases moving up and down functor categories.</p>
<p>By far the best part of this approach is the style of proof. By leveraging continuity properties, characterizations in terms of (parameterized) representability, some general isomorphisms, and occasionally some hand-crafted isomorphisms, nearly any categorical theorem can be proven in a dozen or less isomorphisms. The presentation looks and feels very much like solving an algebraic equation. The proofs are easy to read and easy to write.</p>
<p>The main drawback of this style is that most of the properties above weaken and some disappear when working in enriched or higher categories.</p>
<h3 id="cat-category-theory"><strong>Cat</strong>-category theory</h3>
<p>Arguably, this style should be based on universal arrows. While it technically is, in practice, it’s rare that one talks about universal arrows and instead the parameterized version, namely adjunctions in their unit/counit formulation are the main tool. After adjunctions would be Kan extensions. All of these are concepts that live naturally at the level of 2-categories which makes them much easier to generalize.</p>
<p>The main style of proof is diagram chasing, i.e. proving typically several equalities. On the one hand, proving an equation is straight-forward equational reasoning; on the other hand, there tend to be several equations that need to be proven at a time, they tend to be fine-grained and thus detailed and tedious, and often general results don’t obviously apply. The solution to most of these problems is to use string diagrams instead. Many of the bureaucratic details completely disappear and the proofs become crystal clear. A wonderful example of this style of proof is proving that an adjunction gives rise to a monad. With normal diagram chasing it’s mildly tedious. With string diagrams it proves itself.</p>
<p>One issue that comes up in this style is the elegant definitions tend to be wholesale. For example, there’s a nice adjunction that characterizes all limits of any given shape. Unfortunately, the adjunction only exists if all the limits of that shape exists. If they don’t all exist, then you need to use some other method to talk about the limits that do exist. Technically, universal arrows could handle this, but usually representability is used instead.</p>
<!-- ### Yoneda-->
<h3 id="conclusion">Conclusion</h3>
<p>Ultimately, one should become familiar with all these approaches. There are definitely problems that fit nicer in some than others. However, when it comes to universal properties the <strong>Set</strong>-category theory wins hands down. <strong>Cat</strong>-category theory tends to be more useful when working with structures that aren’t characterized by a universal property such as monoidal structure. Initiality has its niche with initial algebras. I don’t have any ideas on where it might also be a profitable perspective. In fact, I’m not completely sure it’s a good thing that we think about initial algebras as initial algebras. There are interesting interactions between initial algebras and adjunctions for example and it’s not clear to me that they wouldn’t be more accessible with a different presentation of initial algebras.</p>
<h3 id="texts-illustrating-these-approaches">Texts illustrating these approaches</h3>
<ul>
<li>Representatives of initiality:
<ul>
<li><a href="http://maartenfokkinga.github.io/utwente/mmf92b.pdf">A Gentle Introduction to Category Theory – the calculational approach –</a> by Maarten Fokkinga</li>
</ul></li>
<li>Representatives of <strong>Set</strong>-category theory:
<ul>
<li><a href="http://www.cs.ox.ac.uk/ralf.hinze/publications/WGP10.pdf">Reason Isomorphically!</a> by Ralf Hinze</li>
<li><a href="http://arxiv.org/abs/1501.02503">This is the (co)end, my only (co)friend</a> by Fosco Loregian</li>
<li><a href="http://www.tac.mta.ca/tac/reprints/articles/10/tr10abs.html">Basic Concepts of Enriched Category Theory</a> by G. M. Kelly</li>
</ul></li>
<li>Representatives of <strong>Cat</strong>-category theory:
<ul>
<li><a href="http://www.dcs.ed.ac.uk/home/dt/CT/categories.pdf">Category Theory Lecture Notes</a> by Daniele Turi</li>
</ul></li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>|{**}| is just some singleton set.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Differentiation under the integral</title>
    <link href="https://derekelkins.github.io/posts/differentiation-under-the-integral.html" />
    <id>https://derekelkins.github.io/posts/differentiation-under-the-integral.html</id>
    <published>2015-09-14T07:53:29Z</published>
    <updated>2015-09-14T07:53:29Z</updated>
    <summary type="html"><![CDATA[<p><a href="../raw/DiffUnderIntegral.pdf">Here</a> is a PDF with an informal proof of a very general form of <a href="https://en.wikipedia.org/wiki/Differentiation_under_the_integral_sign">differentiation under the integral</a>.</p>
<p>It’s formulated using geometric algebra and provides a simple demonstration of using some of the basic identities in geometric calculus.</p>
<p>The end result is:</p>
<p><img src="../raw/diff-under-integral.svg" alt="d/(dt) int_(D(t)) L_t(x; d^m x) = int_(D(t)) dot L_t(x; (d^m x ^^ (del x)/(del t)) * dot grad_x) + int_(del D(t)) L_t(x; d^(m-1) x ^^ (del x)/(del t)) + int_(D(t))(del L_t(x; d^m x))/(del t)"></img></p>
<!--
> `#d/(dt) int_(cc"D"(t)) bb"L"_t(bb"x"; d^m bb"x") 
>    = int_(cc"D"(t)) dot bb"L"_t(bb"x"; (d^m bb"x" ^^ (del x)/(del t)) * dot grad_(bb"x"))#
>  # + int_(del cc"D"(t)) bb"L"_t(bb"x"; d^(m-1) bb"x" ^^ (del x)/(del t))#
>  # + int_(cc"D"(t))(del bb"L"_t(bb"x"; d^m bb"x"))/(del t)#`{.asciimath}
-->]]></summary>
</entry>
<entry>
    <title>A better way to write convolution</title>
    <link href="https://derekelkins.github.io/posts/convolution.html" />
    <id>https://derekelkins.github.io/posts/convolution.html</id>
    <published>2015-09-14T06:12:26Z</published>
    <updated>2015-09-14T06:12:26Z</updated>
    <summary type="html"><![CDATA[<p>Normally discrete convolution is written as follows:</p>
<blockquote>
<p><code class="asciimath">#(f ** g)(n) = sum_(k=0)^n f(k)g(n-k)#</code></p>
</blockquote>
<p>It is not immediately obvious from this that #f ** g = g ** f#. Consider this alternate representation:</p>
<blockquote>
<p><code class="asciimath">#(f ** g)(n) = sum_(j+k=n) f(j)g(k)#</code></p>
</blockquote>
<p>This formula is obviously symmetric in #f# and #g# and it clarifies an important invariant. For example, to multiply two polynomials (or formal power series) we convolve their coefficients. This looks like:</p>
<p>Let <code class="asciimath">#P(x) = sum_k a_k x^k# and #Q(x) = sum_k b_k x^k#</code> then</p>
<blockquote>
<p><code class="asciimath">#P(x)Q(x) = sum_(j+k=n) a_j b_k x^n#</code></p>
</blockquote>
<p>This emphasizes that the #n#th coefficient is the product of the coefficients whose degrees sum to #n#. (You may recognize this as the convolution theorem.)</p>
<!--more-->
<p>There is one subtle difference. In this alternate representation, it very much matters what the domain of #j# and #k# are. If #j# and #k# are naturals, we get what we started with. But if they are integers, then we have:</p>
<blockquote>
<p><code class="asciimath">#sum_(j+k=n) f(j)g(k) = sum_(k=-oo)^oo f(k)g(n-k)#</code></p>
</blockquote>
<p>In many combinatorial situations this makes no difference and may even be preferable. If, however, you are doing something like a short-time Fourier transform, then you probably don’t want to include an infinite number of entries (but you probably aren’t indexing by #bbbZ#). Personally, I view this as a feature; you should be clear about the domain of your variables.</p>
<p>Let’s prove that #**# is associative, i.e. <code class="asciimath">#((f ** g) ** h)(n) = (f ** (g ** h))(n)#</code>. Expanding the left hand side we get:</p>
<blockquote>
<p><code class="asciimath">#sum_(m+k=n) sum_(i+j=m) f(i)g(j)h(k)# #= sum_(i+j+k=n) f(i)g(j)h(k)# #= sum_(i+m=n) sum_(j+k=m) f(i)g(j)h(k)#</code></p>
</blockquote>
<p>and we’re done. It’s clear the associativity of convolution comes from the associativity of addition and distributivity. In fact, the commutativity also came from the commutativity of addition. This suggests a simple but broad generalization. Simply replace the #+# in the indexing with any binary operation, i.e.:</p>
<blockquote>
<p><code class="asciimath">#(f ** g)(n) = sum_(j o+ k=n) f(j)g(k)#</code></p>
</blockquote>
<p>Usually #o+# is taken to be an operation of a group, and this makes sense when you need to support the equivalent of #n-k#, but there’s really nothing keeping it from being a monoid, and the unit isn’t doing anything so why not a semigroup, and we only really need associativity if we want the convolution to be associative, and nothing requires #n# to be the same type as #j# or #k# or for them to be the same type as each other for that matter… Of course having a group structure reduces the often sticky problem of factoring #n# into all the pairs of #j# and #k# such that #j o+ k = n# to the problem of “simply” enumerating the group.</p>
<p>Here’s some code for the free monoid (i.e. lists) case:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Data.Monoid</span>
<span class="kw">import </span><span class="dt">Data.List</span>

<span class="kw">class</span> <span class="dt">Monoid</span> m <span class="ot">=&gt;</span> <span class="dt">CommutativeMonoid</span> m
<span class="kw">instance</span> <span class="dt">Num</span> a <span class="ot">=&gt;</span> <span class="dt">CommutativeMonoid</span> (<span class="dt">Sum</span> a)

<span class="co">-- Overly generalized convolve</span>
<span class="ot">ogconvolve ::</span> (<span class="dt">CommutativeMonoid</span> m) <span class="ot">=&gt;</span> (a <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> m) <span class="ot">-&gt;</span> (n <span class="ot">-&gt;</span> [(j,k)]) <span class="ot">-&gt;</span> (j <span class="ot">-&gt;</span> a) <span class="ot">-&gt;</span> (k <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> n <span class="ot">-&gt;</span> m
ogconvolve mul factor f g n <span class="fu">=</span> mconcat (map (uncurry (\j k <span class="ot">-&gt;</span> mul (f j) (g k))) (factor n))

<span class="ot">gconvolve ::</span> <span class="dt">Num</span> m <span class="ot">=&gt;</span> (n <span class="ot">-&gt;</span> [(n,n)]) <span class="ot">-&gt;</span> (n <span class="ot">-&gt;</span> m) <span class="ot">-&gt;</span> (n <span class="ot">-&gt;</span> m) <span class="ot">-&gt;</span> n <span class="ot">-&gt;</span> m
gconvolve factor f g n <span class="fu">=</span> getSum (ogconvolve (\a b <span class="ot">-&gt;</span> <span class="dt">Sum</span> (a<span class="fu">*</span>b)) factor f g n)

<span class="ot">lconvolve ::</span> <span class="dt">Num</span> m <span class="ot">=&gt;</span> ([a] <span class="ot">-&gt;</span> m) <span class="ot">-&gt;</span> ([a] <span class="ot">-&gt;</span> m) <span class="ot">-&gt;</span> [a] <span class="ot">-&gt;</span> m
lconvolve <span class="fu">=</span> gconvolve (\as <span class="ot">-&gt;</span> zip (inits as) (tails as))</code></pre></div>
<p>You may have noticed that we never actually use #o+# anywhere. It’s only significance is to define the valid factorizations. I.e. there’s an implicit constraint in the above code that</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">all (\(j,k) <span class="ot">-&gt;</span> n <span class="fu">==</span> j <span class="ot">`oplus`</span> k) (factor n)</code></pre></div>
<p>and also that</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">factor n <span class="fu">==</span> nub (factor n)</code></pre></div>
<p>i.e. no duplicates. (Conceptually, factor spits out a set, indeed the graph of the relation #(j,k)|-&gt;j o+ k=n#.)</p>
<p>The commutative monoid constraint and <code>mul</code> function were just for the heck of it, but why a commutative monoid and not an arbitrary monoid? Well, we don’t want the result to depend on how <code>factor</code> spits out the factors. In other words, if it actually did return a set then we can’t depend on the order of the elements in the set if we want a well-defined function.</p>
<p>Here’s where I tell you that <code>lconvolve</code> is an important function for something. I suspect it or a variant probably is, but I don’t know. Here’s another monoid case, commutative this time, that definitely is important and interesting: <a href="https://en.wikipedia.org/wiki/Dirichlet_convolution">Dirichlet convolution</a>.</p>
<p>Here’s the typical bad definition:</p>
<blockquote>
<p><code class="asciimath">#(f *** g)(n) = sum_(d|n) f(d)g(n/d)#</code> where #d|n# means #d# evenly divides #n#.</p>
</blockquote>
<p>These are the coefficients of the product of two Dirichlet series. For example,</p>
<blockquote>
<p><code class="asciimath">#F(s) = sum_(n=1)^oo f(n)n^(-s) \quad G(s) = sum_(n=1)^oo g(n)n^(-s)#</code> <code class="asciimath">#\quad F(s)G(s) = sum_(n=1)^oo (f *** g)(n)n^(-s)#</code></p>
</blockquote>
<p>We again see a situation where the correspondence doesn’t just jump out at you (or at least it didn’t to me originally) until you realize the above sum can be written:</p>
<blockquote>
<p><code class="asciimath">#(f *** g)(n) = sum_(ab=n) f(a)g(b)#</code></p>
</blockquote>
<p>then it’s pretty easy to see that it is right. We can start doing a lot of number theory with the above combined with the <a href="https://en.wikipedia.org/wiki/Euler_product">Euler product</a> formula:</p>
<blockquote>
<p><code class="asciimath">#sum_(n=1)^oo f(n)n^(-s) = prod_(p\ &quot;prime&quot;) sum_(n=0)^oo f(p^n)p^(-ns)#</code></p>
</blockquote>
<p>where #f# is multiplicative, which means #f(ab) = f(a)f(b)# when #a# and #b# are coprime. (The real significance of #f# being multiplicative is that it is equivalent to #f# being completely determined by its values on prime powers.) It turns out it is surprisingly easy and fun to derive various <a href="https://en.wikipedia.org/wiki/Arithmetic_function">arithmetic functions</a> and identities between them. Here’s a brief teaser.</p>
<p>#1(n) = 1# is a multiplicative function and this gives:</p>
<blockquote>
<p><code class="asciimath">#zeta(s) = sum_(n=1)^oo n^(-s) = prod_(p\ &quot;prime&quot;) 1/(1-p^(-s))#</code></p>
</blockquote>
<p>where we’ve used the formula for the sum of a geometric series.</p>
<p>So <code class="asciimath">#1/(zeta(s)) = prod_(p\ &quot;prime&quot;) 1-p^(-s) = sum_(n=1)^oo mu(n)n^(-s)#</code>. The question is now, what is #mu#? Well, all we need to do is say what it is on prime powers and comparing the Euler product formula to the above we see, for prime #p#, #mu(p) = -1# and #mu(p^n) = 0# for #n &gt; 1#. This is the <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_function">Möbius function</a>. Because #zeta(s) * (1/(zeta(s))) = 1# we have #(1 *** mu)(n) = sum_(d|n) mu(d) = 0# for #n &gt; 1#. Continuing in this vein leads to analytic number theory and the Riemann hypothesis, though you may want to pick up the <a href="https://en.wikipedia.org/wiki/Mellin_transform">Mellin transform</a> along the way.</p>]]></summary>
</entry>
<entry>
    <title>First post</title>
    <link href="https://derekelkins.github.io/posts/first-post.html" />
    <id>https://derekelkins.github.io/posts/first-post.html</id>
    <published>2015-09-14T06:12:11Z</published>
    <updated>2015-09-14T06:12:11Z</updated>
    <summary type="html"><![CDATA[<p>I finally made a blog. We’ll see how it goes. Right now I’m in a kind of mathy mood so the coming posts will probably be pretty theoretical/mathematical. I do have a list of topics I’d like to write about, so I should be producing something for a while. If there’s something you’d like me to talk about, email me.</p>]]></summary>
</entry>

</feed>
